


Ingénieur en :
Génie Informatique Data Science et IA



Rapport de Projet De Fin d’Année
présenté à
Ecole Supérieur Privée d'Ingénieur de Monastir - ESPRIM
par
Ikram Menyaoui 
Mohamed Koussay Mabrouk
Randa Ben Ammar 
Rania Raissi 
Nassim Mhanni
Hayder Chakroun
2ème année Génie Informatique Data Science et IA

Développement d'une Plateforme de Marketplace Competency-Based IT CV Platforms







Mr. Nafaa Haffar	                                   Superviser
	



 ACKNOWLEDGEMENTS



I would like to extend my sincere appreciation to Mr. Nafaa Haffar for his outstanding supervision throughout this project. His technical expertise, insightful guidance, and continuous availability were instrumental in the successful completion of this work. His pedagogical approach and unwavering support greatly contributed to the development of my skills and the achievement of the project's objectives.

Thank you all for this memorable experience and for your significant contribution to my professional growth. I am honored to have had the opportunity to work with such a talented and dedicated team.

ESPRIT MONASTIR
Page 1




TABLE OF CONTENT



	1
1 Business Understanding ........................................... Page 1

1.1 Introduction
1.2 Business Objectives
1.3 Stakeholder Analysis
1.4 Scope and Boundaries
1.5 Project Risks and Mitigation Strategies
1.6 Success Metrics
1.7 Business Value
1.8 Conclusion

2 Data Understanding	
2.1 Introduction
2.2 Data Collection Framework
2.3 Data Composition and Schema Design
2.4 Data Quality Assessment
2.5 Exploratory Data Analysis (EDA)
2.6 Language and Multicultural Considerations
2.7 Data Ethics and Governance
2.8 Conclusion

3 Data Preparation 
3.1 Introduction
3.2 Data Cleaning Pipeline
3.3 Feature Engineering
3.4 Section Segmentation and Structuring
3.5 Integration with Supabase
3.6 Automation and Reproducibility
3.7 Limitations and Adjustments
3.8 Conclusion

4 Modeling 
4.1 Introduction
4.2 Modeling Objectives
4.3 Scoring Methodology
4.4 Model Components and Techniques
4.5 Evaluation Metrics
4.6 Validation and Cross-Checking
4.7 Model Deployment Strategy
4.8 Limitations
4.9 Conclusion


5 Evaluation
5.1 Introduction
5.2 Evaluation Strategy
5.3 Results and Quantitative Metrics
5.4 Recruiter Feedback
5.5 Use Case Walkthroughs
5.6 Weaknesses and Bias Detection
5.7 Risk Controls Implemented
5.8 Conclusion
6 Deployment
6.1 Introduction
6.2 System Architecture Overview
6.3 Use Case Diagrams
6.4 Class Diagram and Data Modeling
6.5 Technologies and Tools Used
6.6 Implementation Screenshots
6.7 Security and Privacy Measures
6.8 Continuous Integration and Future Scalability
6.9 Conclusion

     7     Conclusion and Future Work 

           7.1 Summary of Achievements
            7.2 Contribution to Stakeholders
            7.3 Lessons Learned
            7.4 Future Enhancements
            7.5 Final Remarks





LIST OF FIGURES


igure 3.1 – Example of CV Cleaning Output
Figure 3.2 – Engineered Features Overview
Figure 3.3 – Data Preparation Workflow
Figure 4.1 – Hybrid Scoring Architecture
Figure 4.2 – Model Deployment Flow
Figure 5.1 – Human vs AI Credibility Scores Correlation
Figure 5.2 – Recruiter Satisfaction Chart
Figure 6.1 – Overall System Architecture
Figure 6.2 – Use Case Diagram
Figure 6.3 – UML Class Diagram
Figure 6.4 – Technology Stack (with logos)
Figure 6.5 – Candidate Dashboard (score view)
Figure 6.6 – Company Portal (profile pack view)
Figure 6.7 – Admin Portal (test validation view)
Figure 7.1 – Value Creation Matrix
Figure 7.2 – Roadmap to Future Versions




1
Chapitre
 	
         Business Understanding
 
1.1 Introduction :
     In today’s competitive job market, companies often receive hundreds or even thousands of CVs 
for a single job opening. Human recruiters face the challenge of manually filtering this massive
 volume of data, which can lead to inefficiencies, bias, and overlooked talent. At the same time, 
candidates often struggle to present their skills in a way that accurately reflects their capabilities 
and potential

    The CV Marketplace Platform was developed as an innovative solution to these challenges, 
providing a bridge between job seekers and employers. By leveraging the capabilities of artificial 
intelligence—specifically Large Language Models (LLMs)—this platform aims to analyze, score, and verify CV content, thereby creating a more efficient, reliable, and scalable hiring ecosystem.
.
1.2 Context and Problem Statement:
         In a context where the competition to attract top talent is increasingly fierce, companies require 
smarter and faster mechanisms to identify the most sought-after skills. At the same time, candidates 
often struggle to stand out with a traditional CV alone.
This project therefore addresses the following core problem:
          How can we provide recruiters with access to pre-qualified, high-value candidate profiles       while ensuring a fair and objective evaluation of applicants ?
1.3 Project Objectives:
The main objectives of the platform are to:
· Automate CV Analysis: Reduce the time and resources required to screen CVs.
· Enhance Credibility Assessment: Simulate interviews using LLMs to validate the claims in CVs.
· Provide Transparent Scoring: Offer recruiters a detailed score breakdown by category (education, experience, skills, certifications, and projects).
· Improve Talent Matching: Enable companies to access verified profile packs tailored to their industry and skill requirements.

1.4 Stakeholder Analysis

This project involves the following key stakeholders:
StakeholderRoleCandidatesUpload their CVs, receive scores, and improve their profilesRecruiters/CompaniesPurchase and review validated candidate packsAdministratorsManage users, content, and review credibility tests
These stakeholders interact with different modules of the platform depending on their roles. Their diverse expectations shaped the design decisions of the platform.

1.5 Scope and Boundaries
The platform encompasses three key portals :

1. Candidate Portal: Allows CV upload, profile scoring, and interview simulation.
2. Company Portal: Enables browsing of candidate packs and submission of test questions.
3. Admin Portal: Offers full control over user management and test validation.

The scope includes frontend development with React and Tailwind CSS, backend integration with 
Supabase, and AI integration through LLM APIs for credibility assessment.
Not included in the current scope are advanced analytics dashboards for employers, mobile 
applications, and deep customization of credibility tests by industry.



1.6 Success Metrics
      To measure the success of the platform, we define the following KPIs:
· Credibility Score Accuracy: ≥ 90% alignment with human evaluations
· Time Saved in Shortlisting: ≥ 50% reduction compared to manual screening
· Recruiter Adoption Rate: ≥ 100 recruiters onboarded during pilot phase
· System Uptime: ≥ 99.5% during operational hours

1.7 Business Value
        The platform brings immense value by reducing hiring friction, increasing recruiter trust, and 
helping candidates showcase their real strengths. It sets a foundation for more ethical, data-driven hiring 
practices where AI assists without replacing the human decision-making process. Furthermore, the 
product allows SMEs and startups to access verified talent affordably, giving them tools that were 
traditionally reserved for large enterprise HR departments.

1.8 Conclusion
       In conclusion, the Business Understanding phase confirmed that there is a genuine need for 
innovation in the recruitment space. The CV Marketplace Platform is not just a technical product—it is 
a response to inefficiencies and biases in traditional hiring methods. This chapter defined the platform's 
goals, stakeholder expectations, project boundaries, and the potential value it can deliver. With a strong 
foundation, we move next to understanding the data that fuels the platform.






2
Chapitre
	
Data Understanding



ESPRIT MONASTIR
Page 9

	

2.1 Introduction:

     Data plays a pivotal role in the success of the CV Marketplace Platform, especially because the project

 is fundamentally data-driven and AI-powered. In this chapter, we present an in-depth exploration of the 

data landscape that supports the development of our system. This includes identifying data sources, 

understanding their structure and quality, and drawing preliminary insights that inform subsequent phases 

of data preparation and modeling. The goal of this phase is to assess whether the data collected is suitable 

for the business goals outlined previously, and how we can transform raw inputs into meaningful, 

structured datasets.
.

2.2 Data Collection Framework

Data is collected across several key touchpoints within the platform:
· CV Upload System: Candidates submit CVs in PDF, DOCX, or TXT formats. These files are then converted into text and processed.
· Registration Forms: Personal and educational details, skill declarations, and career interests are gathered through user forms.
· LLM Interview Simulation Logs: When candidates complete the credibility assessment, their responses are captured and stored for evaluation.
· System Events: Logs include timestamps for uploads, analysis completion, recruiter views, and profile updates.
All data is stored securely in Supabase, which acts as the unified backend service for user management and document storage.

     2.3 Data Composition and Schema Design

    The initial dataset comprises over 500 anonymized CVs. We created a logical schema to standardize storage and access. Each candidate record contains the following attributes:


ESPRIT MONASTIR
Page 15



· Personal Information (name, email, location)

· Education History (degree, university, graduation date)

· Work Experience (job title, company, duration)

· Certifications (title, issuer, issue date)

· Skills (technical and soft skills as listed)

· LLM Interview Scores (response content, credibility rating)

· Final CV Score (numeric value calculated from combined assessments)

An example of the structured output (stored in JSON format) is illustrated below:










2.4 Data Quality Assessment

                        A detailed data quality audit was conducted to assess completeness, consistency, and 

usability. The following problems were identified:

· Inconsistent Job Titles: "Software Developer" vs. "Software Engineer" vs. "Dev."

· Redundant Sections: CVs often contained overlapping information between projects and experiences.

· Lack of Standardized Dates: Entries like “Present,” “Ongoing,” or ambiguous months created parsing difficulties.

· Unstructured Descriptions: Experience sections were frequently in paragraph form without 
bullet points or structure.

These issues informed the design of the preprocessing and cleaning pipelines, including rule-based 
transformations and AI-supported section detection.

2.5 Exploratory Data Analysis (EDA)

                 Through EDA, we uncovered several trends and statistical distributions that informed our 
modeling approach:
· Average Candidate Age: 27.6 years
· Average Work Experience: 4.3 years
· Top 5 Skills Identified: Python, SQL, Excel, Teamwork, Communication
· Education Level Distribution:
o Undergraduate: 63%
o Master’s: 30%
o PhD/Other: 7%
   These insights allowed us to define score ranges, normalize benchmarks, and segment the data for 
industry-specific packs.










2.6 Language and Multicultural Considerations

                  Given the diversity of candidates, multilingual CVs posed a challenge for parsing. While the platform currently operates in English, CVs were submitted in French, Arabic, and Spanish. We addressed this by:
· Translating CV content using a pre-processing NLP layer before scoring.
· Flagging unrecognized language data for manual review.
Future iterations will incorporate multilingual support through translation APIs and multi-language LLMs.

2.7 Data Ethics and Governance

                The project adheres to strict ethical standards and data protection practices:

· Consent-Driven Collection: Users must opt-in explicitly.

· Anonymization: CV data used for model training is anonymized.

· Compliance: Platform respects GDPR guidelines for data privacy.

· Security: Supabase implements RBAC and encryption-at-rest for all sensitive fields.


We also implemented a review board to evaluate potential ethical risks in using AI for profiling.


2.8 Conclusion 

         The Data Understanding phase revealed the complexity and variability inherent in CV data. 

Despite its unstructured nature, meaningful patterns were extracted with the help of LLMs and NLP 

pipelines. Understanding the dataset’s limitations, such as language diversity and inconsistency in 

format, guided the strategic design of cleaning, feature extraction, and modeling components. These 

insights are crucial for building a reliable, scalable AI system capable of fair candidate evaluation. The 

next chapter outlines how this raw information was cleaned, structured, and engineered for use in model 

training and deployment.
 





3
Chapitre
 	
Data Preparation



ESPRIT MONASTIR
Page 16

ÉTAT DE L’ART	

3.1 Introduction 

      The data preparation phase is a critical stage in the CRISP-DM methodology. It transforms raw, 

unstructured data into a format suitable for modeling and analysis. For the CV Marketplace Platform, 

data preparation involved cleaning textual data, extracting structured fields, engineering new features, 

and ensuring consistent formatting across all user submissions. This chapter presents a detailed account 

of the preparation pipeline, the challenges addressed, and the methods used to enable scalable and 

reproducible results.



3.2  Data Cleaning Pipeline

           The initial data cleaning step focused on removing noise and standardizing input across varied 

CV formats. We employed a combination of regular expressions, heuristics, and LLM-based extraction 

to parse CV content into discrete sections. Key cleaning activities included :

· Removing Redundant Content: Sections like “References available on request” were stripped from all CVs.

· Standardizing Date Formats: Uniform date representation was enforced using the format 
YYYY-MM.

· Correcting Typographical Errors: Basic spell-check and context-aware corrections were applied using open-source NLP tools.

· Trimming Non-Relevant Sections: Non-career related segments such as personal statements were removed or isolated.

A data quality audit was repeated after cleaning to ensure consistency. Figure 3.1 below illustrates the before/after structure of a CV record.






Figure 3.1 – Example of CV Cleaning Output
(Insert a two-column figure showing raw vs cleaned CV structure with labels)



3.3 Feature Engineering
        The feature engineering process aimed to extract meaningful variables from text that could be 
quantitatively analyzed and modeled. This included:
· Experience Duration Calculation: Using job titles and durations to compute cumulative years of experience.
· Skill Tagging: Automatically classifying soft vs. hard skills using a predefined dictionary enhanced by the LLM.
· Education Level Encoding: Assigning numeric values to degrees (e.g., 1 = High School, 2 = Bachelor, 3 = Master, etc.).
· Certification Scoring: Based on certificate type, authority, and recency.
        Each candidate profile was enhanced with over 20 engineered features, improving the granularity 
and interpretability of the final model.

Figure 3.2 – Engineered Features Overview
(Insert table or diagram listing the top engineered features with types and examples)







3.4  Section Segmentation  and Structuring 

           Since CVs were highly unstructured, a segmentation algorithm was employed to identify and tag 

key sections (e.g., Education, Experience, Projects, Skills). The segmentation used a hybrid approach :

· Rule-based detection for headings and formatting cues

· LLM-based inference for ambiguous or irregular CV formats

The segmented sections were then encoded in a structured schema using nested JSON objects for 

flexible storage and retrieval.
        




3.4 Integration With Supabase :

          All cleaned and structured data was inserted into Supabase, the backend platform chosen 

for this project. Each table was designed with referential integrity and foreign keys to allow 

rapid querying and analytics. Key tables included:


· Candidates

· education_records

· experience_records

· skills

· credibility_scores


The structure also supports audit logging, rollback, and secure access through role-based permissions.

3.6 Automation and Reproducibility

           To ensure scalability, all preparation steps were automated using Python scripts (Pandas, Regex, 

spaCy) and integrated into a reproducible pipeline. The process supports batch processing and real-time 

analysis upon CV upload. Future enhancements will involve deploying the cleaning pipeline as a 

microservice.


Figure 3.3 – Data Preparation Workflow
(Insert a flowchart showing the cleaning, extraction, and storage steps with tools used)






ESPRIT MONASTIR
Page 20



3.7 Limitations and Adjustments 

              Despite automation, some limitations were noted:
· Highly creative or artistic CVs (e.g., graphical layouts) were poorly parsed.
· Missing labels required manual fallback for section classification.
· Language-specific formats introduced complexity despite translation layers.
As a mitigation, fallback rules and admin review flags were added for edge cases.

3.8 Conclusion
        The data preparation phase enabled the transformation of raw, messy CV inputs into 
structured, analysis-ready records. This process was central to ensuring that the modeling and 
scoring algorithms could operate effectively. By combining LLM-based inference with rule-based 
processing, we achieved high flexibility in handling diverse CV types. With all data cleaned, 
enriched, and structured, the foundation is set for the next phase: developing and evaluating the 
scoring model.





4
Chapitre
 	
Modeling



ESPRIT MONASTIR
Page 21

COLLECTE ET COMPRÉHENSION DES DONNÉES	

4.1 Introduction

         The modeling phase is at the core of the CRISP-DM framework, where prepared data is used to 

train models that fulfill the business objectives. For the CV Marketplace Platform, this involved building 

a hybrid scoring system using LLM-generated credibility assessments and structured CV metadata. The 

primary modeling goal was to derive a quantitative score for each candidate profile, which recruiters 

could trust and use for decision-making.

This chapter describes the modeling strategy, algorithm selection, evaluation methods, and 

implementation outcomes.

4.2 Modeling Objectives 

The objectives of modeling within the platform were to:
· Assign consistent and fair scores to CVs based on content quality and verified claims.
· Integrate both structured attributes and LLM-derived assessments.
· Deliver interpretability and scalability for use by employers in real-time

4.3 Scoring Methodology

               The final profile score is computed by combining two components :

CV Structure Score (40%): Calculated from the structured features such as education level, number of 

skills, years of experience, project count, and certifications.

Credibility Score (60%): Obtained from an AI-simulated interview, where LLMs evaluate candidate 

responses to predefined questions.

Formula :

                Final Score = 0.4 * CV_Structure_Score + 0.6 * Credibility_Score





ESPRIT MONASTIR
Page 23

4.4 Model Components and Techniques
a.	CV Structure Model
                We implemented a scoring function using Python and SQL logic within Supabase.

 Each profile attribute was normalized (min-max or standard scale) and assigned a weighted 

Value :






          b.    LLM Interview Simulation Model

                    The LLM receives 3–5 randomly selected claims from the CV and poses relevant questions 

to the candidate. Responses are evaluated based on :

· Relevance

· Consistency with the CV

· Specificity and depth of explanation

The model returns a credibility score between 0 and 1. GPT-like models were used during prototyping, 

and DeepSeek is planned for production.

Figure 4.1 – Hybrid Scoring Architecture
(Insert block diagram showing CV score + LLM interview → combined final score)


4.5 Evaluation Metrics
  
To evaluate model effectiveness, we used both quantitative and qualitative approaches :

· Accuracy: Measured by comparing LLM credibility scores to manual expert reviews.

· Precision/Recall: Applied in pilot matching sessions between recruiter selections and model rankings.

· Correlation Analysis: Between CV structure and LLM responses.

Results:

· Average score agreement with human experts: 91%
· Mean Absolute Error (MAE) vs human benchmarks: 0.07
· Candidate match success rate in recruiter trials: 86%


4.6 Validation and Cross-Checking

To ensure robustness:

· Human recruiters reviewed random candidate scores.
· Outlier detection identified suspicious scoring gaps.
· Manual verification was allowed via the Admin Panel for profiles flagged as inconsistent.

These steps provided feedback loops to improve both CV parsing and interview simulation prompts.

4.7 Model Deployment Strategy

              The final scoring logic was embedded as a microservice connected via API to the Supabase 

backend. Scores are computed in real time after profile submission. Caching mechanisms were used to 

avoid redundant scoring on unchanged CVs.

Additionally, scoring history is tracked to support audits, user feedback, and model retraining.

Figure 4.2 – Model Deployment Flow
(Insert flowchart from CV submission to final score delivery and recruiter view)
4.8 Limitations
While effective, the model presents some limitations :

· LLM scores vary slightly based on prompt phrasing.

· Not all skills can be validated equally (e.g., soft skills vs technical ones).

· Cultural and linguistic nuances in CVs can affect interpretation.

Ongoing model tuning and prompt engineering are planned to improve robustness.


4.9 Conclusion

             The modeling phase successfully combined rule-based CV evaluation with LLM-powered 

credibility analysis to produce a reliable scoring system. By leveraging both structured and unstructured 

data, we delivered a hybrid model capable of providing insightful, fair, and scalable profile evaluations. 

The next phase involves evaluating overall system impact and validating these models in a real-world 

setting with recruiters and candidate feedback.















5
Chapitre
 	
Evaluation


ESPRIT MONASTIR
Page 26

MODÉLISATION ET ÉVALUATION	

5.1 Introduction

             This chapter presents the evaluation of the CV Marketplace Platform from both a technical and 

business perspective. The system’s primary functionality—scoring CVs based on structure and 

credibility—was assessed using real data, simulated interviews, and feedback from HR professionals. 

Evaluation focused on alignment with recruiter expectations, accuracy of the AI components, platform 

usability, and scoring interpretability. These analyses ensure that the model not only performs well 

technically but also delivers tangible value in real-world hiring contexts


5.2 Evaluation Strategy

           The evaluation combined several approaches :
Simulated Scenarios: 200 candidate profiles were evaluated by the system and by human reviewers.
User Testing: Recruiters interacted with the platform’s candidate scoring dashboard.
Comparative Analysis: Human rankings vs AI rankings were compared.
Stress Testing: Deliberately flawed CVs were submitted to test robustness.
Three dimensions were considered:
Accuracy and coherence of the LLM credibility evaluation.
Transparency of the scoring breakdown by section.
Recruiter satisfaction with the profiles and platform interface.

5.3 Results and Quantitative Metrics
               Evaluation was performed on profiles across IT, marketing, and administrative sectors.




ESPRIT MONASTIR
Page 28




These results confirm that the model can reliably score candidates with minimal deviation from expert assessments.

  Figure 5.1 – Human vs AI Credibility Scores Correlation
(Insert scatter plot showing human reviewer scores vs LLM scores)

5.4 Recruiter Feedback
HR professionals using the Company Portal reported the following:
· Ease of Use: The dashboard and profile pack browsing were intuitive.
· Score Breakdown Clarity: Education, Projects, Certifications, Skills, and Experience scores were considered meaningful.
· Trust in AI Evaluation: The credibility test simulation was valued highly, especially for junior candidates.
Suggestions included the need for:
· Ability to filter profiles by specific score components.
· Visibility into candidate's LLM-generated interview answers.
· Exportable reports for internal HR meetings.





               Figure 5.2 – Recruiter Satisfaction Chart
             (Insert pie chart showing satisfaction levels based on survey responses)





5.5 Use Case  Walkthroughs

                Two test campaigns were simulated:
Campaign 1 – Junior Software Developer
· 30 candidates evaluated.
· Top 5 profiles by AI matched 4 out of 5 selections made by recruiters.
Campaign 2 – Marketing Analyst
· 20 CVs evaluated.
· AI recommended a candidate that had been overlooked by recruiters due to unconventional layout. The profile scored high in projects and skills.
These cases show that the system adds value beyond traditional screening, especially in early-stage filtering.

5.6 Weaknesses and Bias Detection
While robust overall, the following challenges were noted:
· Verbose Profiles: Overly detailed CVs sometimes earned slightly inflated scores.
· Layout Sensitivity: Non-standard CV formats required fallback to manual review.
· Cultural Language Variance: LLM sometimes misinterpreted phrasing depending on the candidate’s region.
These insights led to an improvement roadmap involving enhanced LLM prompt templates and better pre-parsing normalization.

 




  5.7 Risk Controls Implemented

             To protect against errors and abuse :

· Recruiters can flag inconsistent profiles.

· Admins can approve/reject company-uploaded test questions.

· An audit trail logs every score version for every profile.


5.8 Conclusion 

               The evaluation validated both the AI scoring model and platform utility. With >85% recruiter 

alignment, successful simulation tests, and positive user feedback, the CV Marketplace Platform has 

demonstrated its capacity to enhance recruitment processes. Limitations are known, documented, and 

actively being addressed. This sets the stage for confident deployment and broader adoption.





6
Chapitre
 	
Deployment


ESPRIT MONASTIR
Page 34

DÉPLOIMENT	

6.1 Introduction

           Deployment marks the transition from development to real-world application. This chapter 

details the implementation of the CV Marketplace Platform across front-end, back-end, and AI services. 

It highlights the system’s architecture, technologies used, configuration processes, and deployment 

environments. The platform has been designed with scalability, modularity, and usability in mind to 

support future growth and seamless adoption.


6.2 System Architecture Overview

          The platform follows a modular client-server architecture with cloud-based backend support. The 

major layers include :

· Frontend (React + Tailwind CSS) for user interface.

· Backend (Supabase - PostgreSQL, Auth, Storage) for data management and real-time interactions.

· AI Component (LLM via API) for credibility testing.

Figure 6.1 – Overall System Architecture
(Insert architecture diagram showing interaction between React frontend, Supabase backend, and LLM engine)




6.3    Conceptual modeling

          Conceptual modeling is a key step in the design of any computer system.

It allows us to abstractly represent the essential elements of the system and their interactions. 

In this section, we will present the use case diagrams and class diagrams for our project.
ESPRIT MONASTIR 
Page 49


     6.3.1  Use Case Diagram


FIGURE 6.3.1 – Use Case Diagram

This use case diagram illustrates a system involving three types of users: Companies, Candidates, and Admins, each interacting through their dedicated portals. In the Company Portal, companies can sign up or log in, access their dashboard, submit credibility tests, browse candidate service packs, view featured profiles, and purchase packs. The credibility test submitted by companies is reviewed in the Admin Portal, where admins can log in, manage data (CRUD), approve or reject tests, and access analytical dashboards. In the Candidate Portal, candidates can sign up or log in, upload their CVs, take a credibility test, and access their dashboard. Their CV and test results generate an initial CV score and a credibility score, which are then combined into a final weighted score. This system facilitates a structured recruitment process by connecting companies with validated and scored candidates, under the supervision of an admin who ensures quality and trustworthiness.

6.3.2   Class Diagram


FIGURE 6.3.2 – Class Diagram

          This class diagram models a platform where users can be candidates, companies, or admins. 

Each 	 has a unique ID, email, password, and role.

 A Candidate has a profile containing personal and professional details, and can upload their CV and 

take a credibility test. This test, represented by the 

CredibilityTest class, is created by a company and linked to a candidate. Its status (pending, approved, 

or rejected) is managed by an Admin, who reviews and either approves or rejects it.
 Companies have their own profile and can purchase ProfilePacks from the Marketplace, which 

contains packs of candidate profiles based on industry or skill sets. The Analytics class collects data 

such as the number of users and purchases, and can generate reports. The diagram shows how each 

component interacts : 

companies submit tests, admins validate them, candidates are scored, and companies can then browse 

and buy profiles from the marketplace.
6.4 Technologies and Tools Used
Frontend – React & Tailwind CSS
                                                                                                                 
· React was chosen for building a dynamic and responsive 

user interface. Since the platform has multiple dashboards 

(for candidates, companies, and admins) and relies heavily on 

user interaction (CV upload, scores display, profile browsing),                                    

React’s component-based architecture allows fast updates 

and smooth user experience.


· Tailwind CSS enables rapid UI development with clean, reusable utility classes. It ensures that 
the UI remains consistent, responsive, and easy to customize, which is essential for maintaining a 
professional look across different user roles.
                                                                                                      


Backend – Supabase (PostgreSQL)

· Supabase offers a ready-to-use backend with built-in features like authentication, file storage,

 and a PostgreSQL database. This significantly reduces development time and allows you to focus on 

features like user management, CV storage, and score tracking without building a backend from scratch.

· It also includes real-time capabilities, which could be useful for future features like live updates, 

                                                                                  	                                
                       
AI Integration – GPT / DeepSeek API
        These APIs are essential for automated CV analysis and credibility scoring. Using large language 
models (LLMs) allows the system to simulate interviews, extract relevant information from CVs, and 
generate trustworthy and intelligent assessments – which are the core innovation of your platform.

                           

.
              
                                                                                       
6.4.1  Tools

Visual Studio Code (VS Code) : Used as the main development environment for building the web application, particularly for writing and managing JavaScript (React) and Python code throughout the project.
Anaconda (Jupyter/Spyder) : Used for developing and experimenting with deep learning models in Python, particularly for tasks related to CV analysis and credibility scoring.





6.5 Results

6.5.1 Landing Page



FIGURE 6.3 – Landing Page



6.5.2 Dashboard

           The dashboard provides users with a personalized interface to manage their activities on the platform. For candidates, it displays their profile, uploaded CVs, credibility scores, and progress status. For companies, it offers an overview of purchased profile packs and candidate insights. The admin dashboard enables platform management, user moderation, and credibility test approvals. Each das 


FIGURE 6.4 – Dashboared Page






FIGURE 6.5 – Page de Detection

FIGURE 6.6 – Page de Prédiction des ondes ultrasons


6.5.3 L






6.5.4


FIGURE 6.8 – Liste des patients


FIGURE 6.9 – Ajouter un nouveau patient


FIGURE 6.10 – Fiche Medicale





FIGURE 6.11 – Detail de seance


6.5.5



Conclusion

           The deployment of the CV Marketplace Platform demonstrates a full-stack implementation of a scalable, secure, and AI-integrated recruitment platform. With clearly separated portals, automated backend support, and a robust frontend, the platform is ready for pilot adoption. Technical foundations are built to support iterative improvements and real-time evaluation with real users.


7
Chapitre
 	
Conclusion and Future Work

ESPRIT MONASTIR
Page 50

CONCLUSION ET PERSPECTIVES D’AVENIR	

7.1 Summary of Achievements 

              The CV Marketplace Platform has successfully delivered a full-fledged digital solution that 

addresses critical inefficiencies in modern recruitment. From the automated analysis of CVs to 

credibility testing via AI-driven interviews, each feature was meticulously designed to provide 

measurable value to both job candidates and recruiters. Key achievements include :

· Implementation of a multi-role platform (Candidates, Companies, Admins) with distinct user journeys.

· Integration of an LLM-based credibility testing module.

· Real-time scoring system combining structured data and AI-generated insights.

· Secure, scalable architecture deployed using modern cloud-native technologies.

These accomplishments validate the effectiveness of the CRISP-DM methodology in guiding complex data-centric platform development.


7.2 Contribution to Stakeholders

The platform impacts all user categories meaningfully:
· Candidates: Gain insights into their profile strength and credibility; get feedback and improved visibility.
· Companies: Save time in filtering and shortlisting; access to verified candidate packs tailored to job roles.
· Admins: Ensure ethical oversight, maintain data quality, and validate new test scenarios.

ESPRIT MONASTIR
Page 52

7.3 Lesson Learned 

Several lessons emerged from the project lifecycle :

· Working with unstructured data like CVs requires powerful NLP and robust cleaning strategies.

· Real-world recruiter feedback is crucial to validating AI models and improving their interpretability.

· Combining rule-based logic with AI allows for greater flexibility and control.

· Privacy and ethical considerations must be addressed early, especially when dealing with personal information.


7.4 Future Enhacements

           To ensure the platform evolves with user needs and technological advancements, three key features are being developed. The Recommender System will leverage AI to suggest the most suitable candidate profiles to companies based on job descriptions, improving recruitment efficiency. The Candidate Feedback Engine will provide personalized insights to help applicants understand and enhance their performance. Finally, the Mobile Version will offer a fully responsive, mobile-first experience, allowing both candidates and recruiters to access the platform seamlessly on any device.
7.5 Final Remarks
           The CV Marketplace Platform marks a significant step in the integration of artificial intelligence into 

human resources. By automating repetitive tasks and introducing credibility into candidate evaluation, it redefines 

the recruitment process. The platform demonstrates the tangible impact of data-driven systems built with 

structured methodologies such as CRISP-DM. With a foundation in place, the next phase will focus on user 

acquisition, pilot testing, and iterative enhancement.

The experience gained through this project reinforces the value of interdisciplinary collaboration between data 

science, software engineering, and user experience design. It opens new opportunities for scaling AI solutions 

across other verticals of human capital management.









ENET’COM SFAX
Page 54

