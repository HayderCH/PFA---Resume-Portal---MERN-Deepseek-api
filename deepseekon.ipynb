{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tiktoken\n",
    "\n",
    "# Replace with your OpenRouter API key\n",
    "API_KEY = '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'\n",
    "API_URL = 'https://openrouter.ai/api/v1/chat/completions'\n",
    "\n",
    "# Define the headers for the API request\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {API_KEY}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Initialize the conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Initialize token counters\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "\n",
    "# Load the tokenizer (use the appropriate encoding for your model)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"Count the number of tokens in a given text.\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    \"\"\"Read the contents of the .txt file and return it as a string.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    return file_content\n",
    "\n",
    "def chat_with_deepseek(user_input):\n",
    "    global input_tokens, output_tokens\n",
    "\n",
    "    # Read the .txt file if provided\n",
    "  \n",
    "\n",
    "    file_content = read_txt_file(\"resume_files\\\\try.txt\")\n",
    "\n",
    "\n",
    "    # Combine the user's input and the file content into a single prompt\n",
    "    combined_input = \"this a an extracted text of a resume \"+file_content + \"\\n\" + user_input\n",
    "    # Append the user's combined message to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": combined_input})\n",
    "\n",
    "    # Count tokens for the user's input and add to the input token counter\n",
    "    user_input_tokens = count_tokens(combined_input)\n",
    "    input_tokens += user_input_tokens\n",
    "\n",
    "    # Define the request payload (data) with the conversation history\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat:free\",\n",
    "        \"messages\": conversation_history\n",
    "    }\n",
    "\n",
    "    # Send the POST request to the DeepSeek API\n",
    "    response = requests.post(API_URL, json=data, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Get the assistant's response\n",
    "        assistant_response = response.json()['choices'][0]['message']['content']\n",
    "        \n",
    "        # Append the assistant's response to the conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "        # Count tokens for the assistant's response and add to the output token counter\n",
    "        assistant_response_tokens = count_tokens(assistant_response)\n",
    "        output_tokens += assistant_response_tokens\n",
    "\n",
    "        # Print the assistant's response\n",
    "        print(\"Assistant:\", assistant_response)\n",
    "        print(f\"Tokens used - Input: {user_input_tokens}, Output: {assistant_response_tokens}\")\n",
    "    else:\n",
    "        print(\"Failed to fetch data from API. Status Code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data from API. Status Code: 401\n"
     ]
    }
   ],
   "source": [
    "chat_with_deepseek('''{\n",
    "  \"full_name\": \"string\",\n",
    "  \"phone_number\": \"string\",\n",
    "  \"email\": \"string\",\n",
    "  \"residence\": \"string\",\n",
    "  \"linkedin\": \"string\",\n",
    "  \"github\": \"string\",\n",
    "  \"about_me\": \"string\",\n",
    "  \"personal_projects\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"academic_projects\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"professional_projects\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"education\": {\n",
    "    \"licence\": [\n",
    "      {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "    ],\n",
    "    \"master\": [\n",
    "      {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "    ],\n",
    "    \"phd\": [\n",
    "      {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "    ]\n",
    "  },\n",
    "  \"engineering_entreprise_work\": [\n",
    "    {\"job_title\": \"string\",\"entreprise\":\"string\", \"description\": \"string\", \"start_date\": \"string\", \"end_date\": \"string\"}\n",
    "  ],\n",
    "  \"non_engineering_work\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"start_date\": \"string\", \"end_date\": \"string\"}\n",
    "  ],\n",
    "  \"certifications\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"extra_curricular_activities\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"string\"\n",
    "  ],\n",
    "  \"books\": [\n",
    "    \"string\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"string\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tiktoken\n",
    "import json\n",
    "\n",
    "# Replace with your OpenRouter API key\n",
    "API_KEY = 'your-api-key'\n",
    "API_URL = 'https://openrouter.ai/api/v1/chat/completions'\n",
    "\n",
    "# Define the headers for the API request\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {API_KEY}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Initialize the conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Initialize token counters\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "\n",
    "# Load the tokenizer (use the appropriate encoding for your model)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"Count the number of tokens in a given text.\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    \"\"\"Read the contents of the .txt file and return it as a string.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    return file_content\n",
    "\n",
    "def chat_with_deepseek(user_input):\n",
    "    global input_tokens, output_tokens\n",
    "\n",
    "    # Read the .txt file if provided\n",
    "    file_content = read_txt_file(\"resume_files\\\\try.txt\")\n",
    "\n",
    "    # Combine the user's input and the file content into a single prompt\n",
    "    combined_input = \"this is an extracted text of a resume \" + file_content + \"\\n\" + user_input\n",
    "    # Append the user's combined message to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": combined_input})\n",
    "\n",
    "    # Count tokens for the user's input and add to the input token counter\n",
    "    user_input_tokens = count_tokens(combined_input)\n",
    "    input_tokens += user_input_tokens\n",
    "\n",
    "    # Define the request payload (data) with the conversation history\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat:free\",\n",
    "        \"messages\": conversation_history\n",
    "    }\n",
    "\n",
    "    # Send the POST request to the DeepSeek API\n",
    "    response = requests.post(API_URL, json=data, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Get the assistant's response\n",
    "        assistant_response = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "        # Append the assistant's response to the conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "        # Count tokens for the assistant's response and add to the output token counter\n",
    "        assistant_response_tokens = count_tokens(assistant_response)\n",
    "        output_tokens += assistant_response_tokens\n",
    "\n",
    "        # Print the assistant's response\n",
    "        print(\"Assistant:\", assistant_response)\n",
    "        print(f\"Tokens used - Input: {user_input_tokens}, Output: {assistant_response_tokens}\")\n",
    "\n",
    "        # Save the JSON response to a file\n",
    "        with open(\"output_response.json\", \"w\") as json_file:\n",
    "            json.dump(response.json(), json_file, indent=4)\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to fetch data from API. Status Code:\", response.status_code)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON data found in the response.\n",
      "Tokens used - Input: 903, Output: 736\n"
     ]
    }
   ],
   "source": [
    "chat_with_deepseek('''now i want you to classify it based on this json format: {\n",
    "  \"full_name\": \"string\",\n",
    "  \"phone_number\": \"string\",\n",
    "  \"email\": \"string\",\n",
    "  \"residence\": \"string\",\n",
    "  \"linkedin\": \"string\",\n",
    "  \"github\": \"string\",\n",
    "  \"about_me\": \"string\",\n",
    "  \"personal_projects\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"academic_projects\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"professional_projects\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"education\": {\n",
    "    \"licence\": [\n",
    "      {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "    ],\n",
    "    \"master\": [\n",
    "      {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "    ],\n",
    "    \"phd\": [\n",
    "      {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "    ]\n",
    "  },\n",
    "  \"professional_work\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"start_date\": \"string\", \"end_date\": \"string\"}\n",
    "  ],\n",
    "  \"certifications\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"extra_curricular_activities\": [\n",
    "    {\"name\": \"string\", \"description\": \"string\", \"date\": \"string\"}\n",
    "  ],\n",
    "  \"skills\": [\n",
    "    \"string\"\n",
    "  ],\n",
    "  \"books\": [\n",
    "    \"string\"\n",
    "  ],\n",
    "  \"languages\": [\n",
    "    \"string\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseekon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
